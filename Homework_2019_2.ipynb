{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "Instructions: Problem sets should be done in the groups formed in the begging of the class. Any issues across group members please reach out to the OSE (office of student engagement) .\n",
    "\n",
    "Each group hands in one copy of their answers.  Be brief and to the point, but be sure to explain your logic. \n",
    "\n",
    "Answer each question in the designated space below, but feel free to creat new cells as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group members names\n",
    "\n",
    "Please write names below\n",
    "\n",
    "* [Name 1]\n",
    "* [Name 2]\n",
    "* [Name 3]\n",
    "* [Name 4]\n",
    "* [Name 5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data set\n",
    "\n",
    "In this first section, you will analyze some variables/features returns of Industry portfolios.\n",
    "\n",
    "Before coding, you guys should try to open this industryPortfolios file and get yourself familiar with what this dataset looks like.\n",
    "\n",
    "Let us get started by downloading the  data from https://www.dropbox.com/s/ginsfhe0w3sr9ij/IndustryPortfolios.csv?dl=0. As what you can see from this file, there are several datasets in it. And we will and need to read different datasets for the following questions. For your convenience, I would recommend you guys use applications like Excel to open it and get a relatively good layout.\n",
    "\n",
    "\n",
    "Now try to using the pandas.read_csv() function. Type ?pandas.read_csv in the console to consult the help file (of use the link https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "\n",
    "- What do you have to do before using pandas?\n",
    "\n",
    "In the pandas.read_csv() function, you should indicate that the data in the CSV file has a header (header argument).\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Create a new variable data_url that contains the URL to the CSV file.\n",
    "\n",
    "   * Tip: you should change the url to https://www.dropbox.com/s/ginsfhe0w3sr9ij/IndustryPortfolios.csv?dl=1 (note the 1 instead of the zero), so the link points directly to the file and not to the dropbox rendering of it.\n",
    "\n",
    "2. Create a new variable aveValWgtRtn_df that contains the data frame with the Average Value Weighted Returns Monthly data.  \n",
    "\n",
    "Hint example:\n",
    "\n",
    "You can see that there are several descriptions on the top of the file, and they may affect the result you read. Then we can try to use pandas's powerful operation parameters to skip them. Try the following command to read it, I will assume you have already have the data_url defined appropriately. And try to use the second command to get the first dataset.\n",
    "\n",
    "aveValWgtRtn_df = pd.read_csv(data_url, skiprows=11, nrows=2236) \n",
    "\n",
    "*  As you can see that there are 11 rows of descriptions.\n",
    "*  And here we are telling pandas that the data ends in row 1000, you should figure out what value to put instead of a 1000 so that the entire data-set is imported. \n",
    "\n",
    "* Remember that  index in programming begins with 0 and you guys should try to figure out where is the end in the following questions.It is ok to do trial and error until you figure out!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0   Food    Beer    Smoke   Games   Books   Hshld   Clths  \\\n",
      "0        192607    0.56   -5.19    1.29    2.93   10.97   -0.48    8.08   \n",
      "1        192608    2.59   27.03     6.5    0.55   10.01   -3.58   -2.51   \n",
      "2        192609    1.16    4.02    1.26    6.58   -0.99    0.73   -0.51   \n",
      "3        192610   -3.06   -3.31    1.06   -4.76    9.47   -4.68    0.12   \n",
      "4        192611    6.35    7.29    4.55    1.66    -5.8   -0.54    1.87   \n",
      "5        192612   -0.51   -4.09    2.55    2.17    0.53    2.56     0.6   \n",
      "6        192701   -0.84    0.57   -0.35    1.87    9.67    4.08   -1.06   \n",
      "7        192702    4.42   12.83    1.49    1.64    1.41    4.57    2.77   \n",
      "8        192703    2.09  -13.56    5.51    1.02   -0.28   -0.08     0.9   \n",
      "9        192704    2.72    2.85    4.01   -3.77   -0.96    1.44    5.95   \n",
      "10       192705    6.13   11.62    11.8    0.18    3.13   10.54    3.37   \n",
      "11       192706   -2.22   10.05    -2.3   -7.74   12.54   -3.03    1.17   \n",
      "12       192707    5.04    4.59    4.39    1.14    1.78     5.5    6.01   \n",
      "13       192708    2.33   -3.98    3.83     6.2    5.46    0.52    1.56   \n",
      "14       192709    6.04    7.01    4.63    4.18   10.04    2.53    4.65   \n",
      "15       192710   -2.46    -0.8   -0.32    0.26    2.63   -1.84    9.65   \n",
      "16       192711    7.17   10.29    6.69    3.58   16.62    2.73    2.06   \n",
      "17       192712    3.53   12.72    1.03    2.81    3.27   10.31   -0.15   \n",
      "18       192801    2.54    0.62   -2.56   -0.37    5.16    3.67    7.07   \n",
      "19       192802   -2.96   -5.22   -5.97   -0.89   -1.75   -0.01   -2.45   \n",
      "20       192803    5.11   14.47    2.34    8.82    5.26    9.99    3.99   \n",
      "21       192804    2.69    4.87   -5.95     5.4   21.23    3.59    9.96   \n",
      "22       192805     1.6    5.48   -0.03    1.85   17.68   -2.52   -0.99   \n",
      "23       192806   -3.93   -4.21    -4.3   -5.05  -10.78   -6.67   -7.13   \n",
      "24       192807    1.06     0.7    3.35    1.56    1.13    0.68    0.53   \n",
      "25       192808    7.85    12.4    3.79    9.48    6.48    9.55    0.18   \n",
      "26       192809    1.74    0.26   -0.39   11.02   -2.36   10.47   -1.13   \n",
      "27       192810   -0.47    4.04    3.44   -1.21    5.62    8.15   -3.55   \n",
      "28       192811    6.62     5.7    6.79    10.4    1.01   16.58    2.56   \n",
      "29       192812    0.56   -3.84   -1.92   -0.66   -0.49   -3.63   -0.38   \n",
      "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "2206     201701   -0.42   -1.41    6.51    1.39    0.53   -1.31   -0.81   \n",
      "2207     201702     0.8     5.7    5.14     1.7   -1.66    -0.1    4.08   \n",
      "2208     201703    1.91    5.81    5.49    2.98   -2.96   -1.36   -0.45   \n",
      "2209     201704    0.24    2.32    0.59    0.79    1.58     4.8    -1.4   \n",
      "2210     201705   -1.99    4.65    5.85   -0.45   -2.89   -5.27     0.3   \n",
      "2211     201706   -0.44   -3.48   -2.83    2.19    1.94    5.52    7.45   \n",
      "2212     201707    -1.3    4.44   -4.29    0.99   -0.45   -0.56    0.51   \n",
      "2213     201708   -1.86   -1.55    3.11   -1.86   -4.99   -5.21   -1.23   \n",
      "2214     201709    2.69    0.62   -1.41    6.38    4.67     7.2    3.46   \n",
      "2215     201710    -1.7    2.53   -0.51   -2.24    0.18   -1.06   -0.31   \n",
      "2216     201711    4.38    3.21    1.23    6.66    8.96    2.19    6.09   \n",
      "2217     201712    6.03    3.29   10.42    1.64   -0.24    0.25    5.91   \n",
      "2218     201801    1.23   -0.19    1.37    3.89    5.76   -2.67    5.57   \n",
      "2219     201802   -4.72    -4.6   -6.31   -3.91   -2.92   -1.55   -2.17   \n",
      "2220     201803   -3.39    3.61   -3.22   -0.53   -0.03    -1.2     5.8   \n",
      "2221     201804    0.43    1.41    -6.1    4.88    1.07    -2.8    1.11   \n",
      "2222     201805     1.7   -2.16    7.99   11.13   -0.86    3.21    5.89   \n",
      "2223     201806    5.13    4.49    8.01    3.53    2.59    3.06   15.22   \n",
      "2224     201807   -0.35   -3.61    5.03    1.19   -3.84   -0.84     1.3   \n",
      "2225     201808     2.6       1   -3.14    4.89   -2.11    3.62    3.66   \n",
      "2226     201809    1.24    1.29   11.29   -1.09   -1.99   -1.99   -1.65   \n",
      "2227     201810   -1.58   -1.41    4.99  -10.51   -8.06   -9.64   -4.95   \n",
      "2228     201811    0.84   -3.36  -14.98    1.12    2.83    3.36    0.57   \n",
      "2229     201812  -12.14    -8.9  -12.83  -10.75  -13.94  -14.41  -11.59   \n",
      "2230     201901   11.41    7.82   14.98   11.77   12.51   13.83   10.33   \n",
      "2231     201902     1.4    -0.3   11.67    2.23    2.38    6.32    6.69   \n",
      "2232     201903     2.1   -3.31    8.97   -2.06   -6.09    1.55    0.14   \n",
      "2233     201904    3.45    5.07   -4.89    3.31   -1.74    2.08    2.82   \n",
      "2234     201905   -6.25   -11.9   -1.83   -9.06   -13.6   -5.29  -12.98   \n",
      "2235     201906    4.59     5.1    0.34    3.05    1.27     5.8    8.18   \n",
      "\n",
      "       Hlth    Chems  ...   Telcm  Servs   BusEq   Paper   Trans   Whlsl  \\\n",
      "0       1.77    8.14  ...    0.83   9.22    2.06     7.7    1.93  -23.79   \n",
      "1       4.25     5.5  ...    2.17   2.02    4.39   -2.38    4.88    5.39   \n",
      "2       0.69    5.33  ...    2.41   2.25    0.19   -5.54    0.05   -7.87   \n",
      "3      -0.57   -4.76  ...   -0.11     -2   -1.09   -5.08   -2.64  -15.38   \n",
      "4       5.42     5.2  ...    1.63   3.77    3.64    3.84     1.6    4.67   \n",
      "5       0.11    5.37  ...    1.99   6.21    7.24   -4.63    3.59    9.65   \n",
      "6       5.05    0.23  ...    1.88   2.08   -1.45    -2.6    1.44  -17.93   \n",
      "7       1.71    9.69  ...    3.97    8.9    4.85    5.46    5.18    3.49   \n",
      "8       1.01    6.07  ...    5.56   -7.8    4.29   -9.67    1.06  -20.47   \n",
      "9       2.74    2.95  ...   -2.13   3.44     3.1    4.93    0.74  -10.75   \n",
      "10      4.12    3.85  ...    3.35  18.33     5.1    5.36    6.92   -4.01   \n",
      "11      0.54   -1.72  ...   -2.14   -6.8    2.73    5.44   -1.97   -4.18   \n",
      "12      9.84   17.69  ...    3.73   2.15    6.19   12.02    6.02   11.11   \n",
      "13      0.28     2.1  ...    0.43   8.06    2.25    3.76   -1.69   -2.58   \n",
      "14      5.65    5.97  ...    6.53   2.15    4.17    3.37    4.31     5.6   \n",
      "15      5.13   -7.46  ...   -2.09   4.97   -4.66    0.14   -4.59  -21.78   \n",
      "16      3.68    9.04  ...    2.83    2.3    9.38   16.87    3.91    -1.3   \n",
      "17     -0.46   -0.23  ...    1.33  -7.83     1.3    1.04     0.1   11.45   \n",
      "18      2.69   -1.08  ...     0.3   0.56    1.18    1.51   -1.23   -0.95   \n",
      "19     -1.38    0.73  ...    -0.3  -0.52    2.02    0.86   -1.35   -8.29   \n",
      "20     10.54   13.16  ...    1.96  -2.44    3.23   11.08    5.78    8.12   \n",
      "21      2.35   -0.26  ...    3.22   2.42     1.6   -0.25    4.37   -5.85   \n",
      "22      9.27    2.98  ...    6.61   0.78    3.88    6.13   -0.46    7.95   \n",
      "23     -3.15   -2.95  ...   -5.22  -5.25   -3.06   -5.74   -3.84   -7.41   \n",
      "24      2.39    1.82  ...   -1.28  -4.94    5.34    4.34   -0.35    0.35   \n",
      "25     14.57    8.89  ...    4.55  15.16    3.01   12.69    4.02    4.06   \n",
      "26     -1.14    3.77  ...    0.15  -0.17    1.81   -1.62    0.28    1.05   \n",
      "27      0.05    5.23  ...    2.97   5.22    1.13   -5.47    -1.3   18.25   \n",
      "28      5.05   12.39  ...    6.68  17.77    8.22     5.1    9.35   11.95   \n",
      "29     -0.41    2.33  ...   -0.38  -7.63    7.49    1.71    0.25   -3.85   \n",
      "...      ...     ...  ...     ...    ...     ...     ...     ...     ...   \n",
      "2206    4.85       1  ...     3.2   2.99    4.07    1.55     1.4       0   \n",
      "2207    6.37    2.02  ...   -0.33   1.09    3.32   -3.12   -0.89    0.52   \n",
      "2208    2.14    3.43  ...    0.63   1.65     2.2    0.24   -5.49   -1.05   \n",
      "2209   -3.11    1.29  ...    6.26   2.79    0.58    1.65    0.14    1.47   \n",
      "2210   -4.94   -3.35  ...   -4.04   1.62    1.51   -1.51   -6.06   -2.61   \n",
      "2211   10.28    0.58  ...    0.37   2.28    0.77    1.07    6.36    1.03   \n",
      "2212   -2.71   -0.74  ...    3.25   0.13    2.28   -0.42   -1.55   -1.25   \n",
      "2213    1.29   -5.28  ...     0.7  -0.31    -2.3   -0.64    2.75   -4.64   \n",
      "2214    8.35    8.36  ...    -0.2   7.05    5.68    6.17   11.17    7.72   \n",
      "2215   -2.34     4.3  ...   -3.13   2.22    0.55    0.22   -1.11   -0.12   \n",
      "2216     2.5    1.03  ...    0.94   2.09    2.47    6.97    5.77    3.17   \n",
      "2217       1   -1.04  ...    4.07   0.73    0.39    2.34   -1.79    3.85   \n",
      "2218    6.89   -0.85  ...    2.12   5.58    3.05    0.89    2.53    2.89   \n",
      "2219   -3.56   -5.02  ...   -3.18  -1.04   -3.18   -8.65   -6.88   -6.62   \n",
      "2220    0.22    2.34  ...   -1.96   0.34    1.05   -3.43    0.77    3.36   \n",
      "2221   -0.21   -0.34  ...   -1.23   1.95   -1.33   -1.95    1.64    -1.1   \n",
      "2222    7.55    4.31  ...   -2.61   5.44    5.75    2.35    8.17    4.87   \n",
      "2223   -2.48   -0.31  ...    7.41   1.01    0.84    0.89    0.37   -0.34   \n",
      "2224    -1.3    2.22  ...   -0.36   0.21    1.17    3.81    3.06    3.09   \n",
      "2225    5.91   -2.72  ...    7.11   6.71    6.78    2.52    0.57    2.93   \n",
      "2226   -1.22    -3.1  ...    1.94  -2.29   -3.74   -0.82     0.5   -0.03   \n",
      "2227  -14.43  -11.97  ...   -5.12  -9.41  -10.94  -12.13  -11.52   -9.96   \n",
      "2228   -0.49    0.29  ...   -1.37    0.1    1.36    0.91   -1.06   -2.17   \n",
      "2229  -18.41  -11.63  ...  -13.75  -9.42  -11.21  -13.23  -18.72  -12.35   \n",
      "2230   18.15   18.32  ...   12.84  14.56   15.34    14.5   14.57   12.27   \n",
      "2231    6.63    5.35  ...     2.6   7.07    6.89    0.52    1.77    2.84   \n",
      "2232    2.97   -5.41  ...    -3.9  -0.29   -1.87   -3.82   -2.81   -2.62   \n",
      "2233   -2.72    5.55  ...    3.44   4.03    6.47    2.83    2.55    4.74   \n",
      "2234   -8.37  -11.96  ...   -5.95  -6.76   -8.92   -9.91  -10.19    -7.5   \n",
      "2235    4.63    7.31  ...    2.35   4.18     7.5    8.16    7.46    6.65   \n",
      "\n",
      "       Rtail   Meals   Fin     Other  \n",
      "0       0.07    1.87    0.37     5.2  \n",
      "1      -0.75   -0.13    4.46    6.76  \n",
      "2       0.25   -0.56   -1.23   -3.86  \n",
      "3       -2.2   -4.11   -5.16   -8.49  \n",
      "4       6.52    4.33    2.24       4  \n",
      "5       0.57    1.51    2.68   -2.34  \n",
      "6       -2.7    1.52   -2.38   -3.96  \n",
      "7       3.47    6.86    2.97    0.28  \n",
      "8       -0.3   -2.42    1.36    2.18  \n",
      "9       4.38    6.56    2.89    5.27  \n",
      "10      2.24    4.62   10.25    1.64  \n",
      "11      -0.7    1.27   -0.03   -3.82  \n",
      "12     10.11    4.68    6.59    6.81  \n",
      "13      7.68    0.55     1.7    5.92  \n",
      "14      7.61    5.94    6.17    0.43  \n",
      "15     -5.03   -1.75     4.1   -3.62  \n",
      "16     12.11    3.01       8   11.19  \n",
      "17     -0.66   -1.56   11.08    1.07  \n",
      "18     -0.85   -1.58    1.45   -3.38  \n",
      "19     -1.04   -2.59   -2.79   -2.68  \n",
      "20      8.69    3.47    9.57    8.85  \n",
      "21     -0.03    0.47    8.87   10.95  \n",
      "22      3.44   14.12    2.28    -0.8  \n",
      "23      -3.4   -2.81   -9.91  -11.95  \n",
      "24      5.72    -0.6    0.29    -0.8  \n",
      "25     13.69   12.37    5.23   12.78  \n",
      "26      0.16   -0.02   12.14   -4.06  \n",
      "27       6.1   -2.19     2.6   -5.21  \n",
      "28     15.52    9.51      10    3.77  \n",
      "29     -1.24    -3.1    1.17  -12.59  \n",
      "...      ...     ...     ...     ...  \n",
      "2206    -5.2   -1.95   -0.45    0.62  \n",
      "2207   -1.45   -2.39    2.62    0.58  \n",
      "2208   -1.14    5.57   -1.23    1.47  \n",
      "2209    1.53    2.36    0.57    -0.8  \n",
      "2210   -5.99   -1.02   -2.56   -0.51  \n",
      "2211   -0.09   -2.06    5.18    0.98  \n",
      "2212   -1.97   -5.65    0.52   -0.68  \n",
      "2213   -4.92   -2.04   -2.35   -2.82  \n",
      "2214    7.61    4.99    7.03    2.46  \n",
      "2215   -5.74    -1.6    1.14   -1.84  \n",
      "2216   11.52     6.5    3.32    0.28  \n",
      "2217    4.48    1.71    -0.8    0.76  \n",
      "2218     0.1    4.26    2.49    0.62  \n",
      "2219   -4.88   -1.26   -2.59   -5.55  \n",
      "2220     0.2    1.62    1.69    1.26  \n",
      "2221    2.87    3.39    0.95   -1.48  \n",
      "2222     4.3    1.54    2.99    3.72  \n",
      "2223    6.62    3.86   -0.21    3.76  \n",
      "2224   -0.83   -1.25     1.1    -3.5  \n",
      "2225    6.49    5.86    1.98    5.47  \n",
      "2226   -3.75   -0.59   -2.28    -2.1  \n",
      "2227   -7.61   -8.95   -7.31   -9.38  \n",
      "2228   -2.61   -1.54    1.75   -1.31  \n",
      "2229  -14.41  -11.36  -10.61   -9.68  \n",
      "2230   13.35     8.6    9.04   14.91  \n",
      "2231    5.06     3.9    5.47    2.53  \n",
      "2232   -4.72   -1.63   -4.41    0.28  \n",
      "2233    0.88    2.22    4.81    1.26  \n",
      "2234  -15.33   -7.97   -5.26   -4.92  \n",
      "2235    5.29    5.28    5.48    2.23  \n",
      "\n",
      "[2236 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_url='https://www.dropbox.com/s/ginsfhe0w3sr9ij/IndustryPortfolios.csv?dl=1'\n",
    "aveValWgtRtn_df=pd.read_csv(data_url, skiprows=11, nrows=2236)\n",
    "print(aveValWgtRtn_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Before you analyze return data, it is a good idea to have (at least) a quick look at the data. Pandas has a number of functions that help you do that:\n",
    "\n",
    "\n",
    "The head() and tail() method shows you the first and the last part of an  object, respectively.\n",
    "The type() function shows you the type of an object.\n",
    "The describe methods provides some useful summaries about the data.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. aveValWgtRtn_df should be a data frame object. Show that this is true.\n",
    "2. Show the first 10 and the last 15 observations of the data. \n",
    "3. Show the number of observations in this dataset (we use this function in the past)\n",
    "4. Show the number of variables in this dataset (we use this function in the past)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "  Unnamed: 0  Food    Beer   Smoke  Games  Books  Hshld  Clths  Hlth   Chems  \\\n",
      "0     192607   0.56   -5.19   1.29   2.93  10.97  -0.48   8.08   1.77   8.14   \n",
      "1     192608   2.59   27.03    6.5   0.55  10.01  -3.58  -2.51   4.25    5.5   \n",
      "2     192609   1.16    4.02   1.26   6.58  -0.99   0.73  -0.51   0.69   5.33   \n",
      "3     192610  -3.06   -3.31   1.06  -4.76   9.47  -4.68   0.12  -0.57  -4.76   \n",
      "4     192611   6.35    7.29   4.55   1.66   -5.8  -0.54   1.87   5.42    5.2   \n",
      "5     192612  -0.51   -4.09   2.55   2.17   0.53   2.56    0.6   0.11   5.37   \n",
      "6     192701  -0.84    0.57  -0.35   1.87   9.67   4.08  -1.06   5.05   0.23   \n",
      "7     192702   4.42   12.83   1.49   1.64   1.41   4.57   2.77   1.71   9.69   \n",
      "8     192703   2.09  -13.56   5.51   1.02  -0.28  -0.08    0.9   1.01   6.07   \n",
      "9     192704   2.72    2.85   4.01  -3.77  -0.96   1.44   5.95   2.74   2.95   \n",
      "\n",
      "   ...  Telcm Servs  BusEq  Paper  Trans   Whlsl  Rtail  Meals  Fin    Other  \n",
      "0  ...   0.83  9.22   2.06    7.7   1.93  -23.79   0.07   1.87   0.37    5.2  \n",
      "1  ...   2.17  2.02   4.39  -2.38   4.88    5.39  -0.75  -0.13   4.46   6.76  \n",
      "2  ...   2.41  2.25   0.19  -5.54   0.05   -7.87   0.25  -0.56  -1.23  -3.86  \n",
      "3  ...  -0.11    -2  -1.09  -5.08  -2.64  -15.38   -2.2  -4.11  -5.16  -8.49  \n",
      "4  ...   1.63  3.77   3.64   3.84    1.6    4.67   6.52   4.33   2.24      4  \n",
      "5  ...   1.99  6.21   7.24  -4.63   3.59    9.65   0.57   1.51   2.68  -2.34  \n",
      "6  ...   1.88  2.08  -1.45   -2.6   1.44  -17.93   -2.7   1.52  -2.38  -3.96  \n",
      "7  ...   3.97   8.9   4.85   5.46   5.18    3.49   3.47   6.86   2.97   0.28  \n",
      "8  ...   5.56  -7.8   4.29  -9.67   1.06  -20.47   -0.3  -2.42   1.36   2.18  \n",
      "9  ...  -2.13  3.44    3.1   4.93   0.74  -10.75   4.38   6.56   2.89   5.27  \n",
      "\n",
      "[10 rows x 31 columns]\n",
      "     Unnamed: 0   Food   Beer    Smoke   Games   Books   Hshld   Clths  \\\n",
      "2221     201804    0.43   1.41    -6.1    4.88    1.07    -2.8    1.11   \n",
      "2222     201805     1.7  -2.16    7.99   11.13   -0.86    3.21    5.89   \n",
      "2223     201806    5.13   4.49    8.01    3.53    2.59    3.06   15.22   \n",
      "2224     201807   -0.35  -3.61    5.03    1.19   -3.84   -0.84     1.3   \n",
      "2225     201808     2.6      1   -3.14    4.89   -2.11    3.62    3.66   \n",
      "2226     201809    1.24   1.29   11.29   -1.09   -1.99   -1.99   -1.65   \n",
      "2227     201810   -1.58  -1.41    4.99  -10.51   -8.06   -9.64   -4.95   \n",
      "2228     201811    0.84  -3.36  -14.98    1.12    2.83    3.36    0.57   \n",
      "2229     201812  -12.14   -8.9  -12.83  -10.75  -13.94  -14.41  -11.59   \n",
      "2230     201901   11.41   7.82   14.98   11.77   12.51   13.83   10.33   \n",
      "2231     201902     1.4   -0.3   11.67    2.23    2.38    6.32    6.69   \n",
      "2232     201903     2.1  -3.31    8.97   -2.06   -6.09    1.55    0.14   \n",
      "2233     201904    3.45   5.07   -4.89    3.31   -1.74    2.08    2.82   \n",
      "2234     201905   -6.25  -11.9   -1.83   -9.06   -13.6   -5.29  -12.98   \n",
      "2235     201906    4.59    5.1    0.34    3.05    1.27     5.8    8.18   \n",
      "\n",
      "       Hlth    Chems  ...   Telcm  Servs   BusEq   Paper   Trans   Whlsl  \\\n",
      "2221   -0.21   -0.34  ...   -1.23   1.95   -1.33   -1.95    1.64    -1.1   \n",
      "2222    7.55    4.31  ...   -2.61   5.44    5.75    2.35    8.17    4.87   \n",
      "2223   -2.48   -0.31  ...    7.41   1.01    0.84    0.89    0.37   -0.34   \n",
      "2224    -1.3    2.22  ...   -0.36   0.21    1.17    3.81    3.06    3.09   \n",
      "2225    5.91   -2.72  ...    7.11   6.71    6.78    2.52    0.57    2.93   \n",
      "2226   -1.22    -3.1  ...    1.94  -2.29   -3.74   -0.82     0.5   -0.03   \n",
      "2227  -14.43  -11.97  ...   -5.12  -9.41  -10.94  -12.13  -11.52   -9.96   \n",
      "2228   -0.49    0.29  ...   -1.37    0.1    1.36    0.91   -1.06   -2.17   \n",
      "2229  -18.41  -11.63  ...  -13.75  -9.42  -11.21  -13.23  -18.72  -12.35   \n",
      "2230   18.15   18.32  ...   12.84  14.56   15.34    14.5   14.57   12.27   \n",
      "2231    6.63    5.35  ...     2.6   7.07    6.89    0.52    1.77    2.84   \n",
      "2232    2.97   -5.41  ...    -3.9  -0.29   -1.87   -3.82   -2.81   -2.62   \n",
      "2233   -2.72    5.55  ...    3.44   4.03    6.47    2.83    2.55    4.74   \n",
      "2234   -8.37  -11.96  ...   -5.95  -6.76   -8.92   -9.91  -10.19    -7.5   \n",
      "2235    4.63    7.31  ...    2.35   4.18     7.5    8.16    7.46    6.65   \n",
      "\n",
      "       Rtail   Meals   Fin    Other  \n",
      "2221    2.87    3.39    0.95  -1.48  \n",
      "2222     4.3    1.54    2.99   3.72  \n",
      "2223    6.62    3.86   -0.21   3.76  \n",
      "2224   -0.83   -1.25     1.1   -3.5  \n",
      "2225    6.49    5.86    1.98   5.47  \n",
      "2226   -3.75   -0.59   -2.28   -2.1  \n",
      "2227   -7.61   -8.95   -7.31  -9.38  \n",
      "2228   -2.61   -1.54    1.75  -1.31  \n",
      "2229  -14.41  -11.36  -10.61  -9.68  \n",
      "2230   13.35     8.6    9.04  14.91  \n",
      "2231    5.06     3.9    5.47   2.53  \n",
      "2232   -4.72   -1.63   -4.41   0.28  \n",
      "2233    0.88    2.22    4.81   1.26  \n",
      "2234  -15.33   -7.97   -5.26  -4.92  \n",
      "2235    5.29    5.28    5.48   2.23  \n",
      "\n",
      "[15 rows x 31 columns]\n",
      "2236\n",
      "473\n"
     ]
    }
   ],
   "source": [
    "print(type(aveValWgtRtn_df))\n",
    "print(aveValWgtRtn_df.head(10))\n",
    "print(aveValWgtRtn_df.tail(15))\n",
    "print(len(aveValWgtRtn_df))\n",
    "print(len(dir(aveValWgtRtn_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Getting indexing right\n",
    "\n",
    "1. It is very important that we get the identity of each observation right\n",
    "2. The identity must be unique so there is not uncertainty when we refer to it\n",
    "3. Note that Pandas created a new column (column 0) that gives the \"name\" to each observation\n",
    "4. It uses as a name a sequence of numbers so each name is unique\n",
    "5. Here we can have a more useful name, the date, which is also unique in this context (there is only one observation per day!)\n",
    "6. In pandas we refer to this identiy as the \"index\" of the dataframe\n",
    "\n",
    "Instructions:\n",
    "1. The .iloc(name) or .loc allow you to retrieve a particular observation, use either of these methods to retrieve the data 11th row in the dataset.\n",
    "2. As you might perceive, apart from the first column, the second column's name is 'Unnamed', but if we refer to the original file, this should be 'Date', now try to replace the name of it with 'Date'.\n",
    "3. Show that now the first colum is the date.\n",
    "4. Now you can try to use original index (0, 1, 2, 3...) to retrieve 3th observation. Which method does not work here?\n",
    "5. Can you use 'Date' to retrieve a certain observation? For example 'Date = 192607'.\n",
    "6. Now use the .loc/.iloc method to retrieve the 'Paper' value in '196308'.\n",
    "7. You can see that for now, the \"Date\" column is still shown as type of int64. However pandas provides us methods to parse the 'Date' to real date format. Now try to use what we have covered in notebook 2 to parse the variables.\n",
    "  \n",
    "   *  Hint: possible solution might looks like:\"aveValWgtRtn_df['Date'] = pd.to_datetime(aveValWgtRtn_df['Date'], error='ignore')\" # Note that this might not work, you should refer to official document of pandas and try to add 'format' parameter into that method, and you also should figure out what the value 'format' parameter should be. Official document url:https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html. Always remember  to refer to official documents can save you a lot of time to learn how to use methods.\n",
    "  \n",
    "8. After you finish this, you may take a look at the change as the result of operation above, try \"print(aveValWgtRtn_df.head())\". And you might think the format of 'Date' is redundant, i.e., we do not need the days. So we can change it's frequency to monthly: \"aveValWgtRtn_df['Date'] = pd.to_datetime(aveValWgtRtn_df['Date'], error='ignore').dt.to_period('M')\".\n",
    "\n",
    "9. Now try to refer to what we have covered in the notebook 2 to change the index to 'Date'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    192705\n",
      "Food            6.13\n",
      "Beer           11.62\n",
      "Smoke           11.8\n",
      "Games           0.18\n",
      "Books           3.13\n",
      "Hshld          10.54\n",
      "Clths           3.37\n",
      "Hlth            4.12\n",
      "Chems           3.85\n",
      "Txtls          13.22\n",
      "Cnstr           7.51\n",
      "Steel           3.22\n",
      "FabPr           8.74\n",
      "ElcEq           8.23\n",
      "Autos           5.54\n",
      "Carry          11.02\n",
      "Mines           0.25\n",
      "Coal            3.19\n",
      "Oil                5\n",
      "Util            9.21\n",
      "Telcm           3.35\n",
      "Servs          18.33\n",
      "BusEq            5.1\n",
      "Paper           5.36\n",
      "Trans           6.92\n",
      "Whlsl          -4.01\n",
      "Rtail           2.24\n",
      "Meals           4.62\n",
      "Fin            10.25\n",
      "Other           1.64\n",
      "Name: 10, dtype: object\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'colnames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-e0525cf89b31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maveValWgtRtn_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcolnames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maveValWgtRtn_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;33m-\u001b[0m \u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'colnames' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(aveValWgtRtn_df.loc[10])\n",
    "colnames(aveValWgtRtn_df)[0] <- \"Date\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Getting the type of the variables right\n",
    "\n",
    "Because pandas is very flexible and can handle multiple types it is very important to check that the type of each variable was imported correctly, otherwise we won't be able to do manipulations \n",
    "\n",
    "Instructions\n",
    "1. Take the mean of Games by writing aveValWgtRtn_df['Games'].mean()\n",
    "2. Open the data set in excel and find what is the term used as a missing value\n",
    "3. Now add na_values='term' to our import code: \n",
    "aapl_df=pandas.read_csv(data_url, na_values='term')\n",
    "4. What is the mean of Game?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Manipulation\n",
    "\n",
    "Lets do something interesting with several pieces within one dataset and several independent datasets.\n",
    "\n",
    "1. We have read the first one dataset into our work space, now let's read the others.\n",
    "\n",
    "Remember our first dataset is \"Average Value Weighted Returns\" and we define it as name of aveValWgtRtn_df. Here, please read the second one \"Average Equal Weighted Return\" dataset as name of \"aveEqlWgtRtn_df\", third \"aveValWgtRtn_al_df\" and then \"aveEqlWgtRtn_al_df\", \"numFrmPrtl_df\", \"aveFrmSize_df\". Note you should follow the step we have covered above including make the data column as index column.\n",
    "\n",
    "2. Use the same method as we have covered in notebook 2, try to add a new column named 'year' valued with the year of the index column for dataset \"aveEqlWgtRtn_df\".\n",
    "\n",
    "3. Let's try to use group the dataset \"aveEqlWgtRtn_df\" by 'year'.\n",
    " \n",
    "4. Can you do this without creating a new column named 'year'? Tip: use year attirbute of index to group by.\n",
    "\n",
    "5. Try to calculate the standard deviation (std) of 'Books' by year. What is the volatility in 2006 and 2008?\n",
    "\n",
    "6. Now try to use concatenate method to put \"aveValWgtRtn_al_df\" and \"aveEqlWgtRtn_al_df\" in the same dataset.\n",
    "\n",
    "7. Now use merge method, to merge datasets \"numFrmPrtl_df\" and \"aveFrmSize_df\" on 'Date' with default setting. Make sure Date have the same type in both data sets before merging.\n",
    "\n",
    "8. Rewrite the merge code above with different merge parameters with 'how = outer', 'how = left' and 'how = right' with dataset \"numFrmPrtl_df\" and \"aveEqlWgtRtn_al_df\". Are the results the same? Can explain why this happens in your own words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Leads and lags\n",
    "\n",
    "Lets compute the growth rate in the number of firms in a given portfolio\n",
    "\n",
    "1. Lets use numFrmPrtl_df\n",
    "\n",
    "2. Compute The growth rate \n",
    "    - we want\n",
    "         Growth[t+1]=(numFrmPrtl_df[t+1]-numFrmPrtl_df[t])/numFrmPrtl_df[t]\n",
    "    - First try Return=(numFrmPrtl_df[1:,:]-numFrmPrtl_df[:-1,:])/numFrmPrtl_df[:-1,:]\n",
    "    - Explain what this command is trying to do?\n",
    "    - Can you Explain why this did not work? \n",
    "3. Now try Growth=(numFrmPrtl_df.values[1:,:]-numFrmPrtl_df.values[:-1,:])/numFrmPrtl_df.values[:-1,:]  \n",
    "   -  here we are directly selecting the values of the dataseries objects\n",
    "   -  Did this work? \n",
    "   -  You may note that, this operation still might have problem, the reason is that, pandas treat those data in original file as type of string instead of 'float' or 'int', now try \"numFrmPrtl_df = numFrmPrtl_df.astype(float)\" to change the data type.\n",
    "4. what did you note about the type of the Growth variable? \n",
    "\n",
    "5. To stay within Pandas dataframe object we have to use the shift method, which takes leads and lags,  where you use numFrmPrtl_df.shift(1) to lag the data one period. You can also type shift(-1) to lead the data.\n",
    "\n",
    "    - So you write Growth_df=(numFrmPrtl_df-numFrmPrtl_df.shift(1))/numFrmPrtl_df.shift(1) \n",
    "    - You have to be very careful using leads and lags, becuase this is literally like using the row above in excel. So you have to make sure that the order of the data set is the way that you need it to be. How do you need the data set to be organized for this operation above to work as intended?\n",
    "\n",
    "6. What are the differences between the Growth_df and Growth objects? What are the similarilities?\n",
    "\n",
    "7. Try to compute the mean of both series. What do you think is going on with the Growth object?\n",
    "\n",
    "8. Using the Growth_df dataframe Compute mean, standard deviation, median, min, max, the date of the minimum return, the date of the maximum return, \n",
    "\n",
    "9. use the .quantile(number) method to find the 5% quantile of average firm size. Explain what this number means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Manipulation 2\n",
    "\n",
    "Let use Average Firm Size dataset this time.\n",
    "\n",
    "1. This time, try to use groupby method, to groupby this dataset by 'Month' and Now calculate the mean value of each industry for every months, Jan, Feb, etc..(Tip: the result should have only 12 rows)\n",
    "\n",
    "2. Now calculate the average growth rate for every month like Jan to Feb, Jul to Aug,and so on. For this, first use the \"shift\" operator to compute the growth rate, than use mean operators to take the mean for a given month. \n",
    "\n",
    "3. Use plot function to output an image with mean and median line for every month for any two industries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Plotting\n",
    "\n",
    "Pandas has built plot functionality that is based on the matplotlib package we say in class\n",
    "\n",
    "It is really easy and intuitive (here the reference: https://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
    "\n",
    "1. Make a time-series plot of the return data (always using Return dataframe object) with columns as \"Food\", \"Beer\" and \"Smoke\" of dataset \"aveEqlWgtRtn_df\" from 1995-2000.\n",
    "\n",
    "   ax1=Return.plot()\n",
    "   \n",
    "2. Make a histogram with 100 bins\n",
    "\n",
    "   ax2=Return.hist(bins=100)\n",
    "   \n",
    "3. Make a plot of the cumulative returns (returns are in precentage, so you should first divide returns by 100)\n",
    "\n",
    "   Tip: Use the method .cumprod()\n",
    "   \n",
    "4. Make a plot of the annual dataset (Average Equal Weighted Returns Annual) with the same column and year we set above.\n",
    "\n",
    " compare with the cumulative return plot. What do you notice? Is this always true?\n",
    "\n",
    "5. Make a plot of the square of returns , this is a good proxy for volatility \n",
    " - use Returns**2\n",
    "\n",
    "6. Add a label to the y-axis, x-axis decribing each varaible plotted (when not generated automatically)\n",
    "\n",
    "  - Tip: use the plot object ax1.(Tab) to find the mehtods that can be used to change the plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
